{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Running sequence:\n",
        "1.   Code Block 1\n",
        "2.   Code Block 2\n",
        "3.   Code Block 3\n",
        "4.   Code Block 4\n",
        "5.   Code Block 5\n",
        "6.   Code Block 6\n",
        "7.   Code Block 7\n",
        "8.   Code Block 8\n",
        "9.   Code Block 9\n",
        "10.  Code Block 10\n",
        "11.  Code Block 11\n",
        "12.  Code Block 12\n",
        "13.  Code Block 13\n",
        "14.  Code Block 14\n",
        "15.  Code Block 16\n",
        "16.  Code Block 17\n",
        "17.  Code Block 18\n",
        "18.  Code Block 19\n",
        "19.  Code Block 21\n",
        "20.  Code Block 22\n",
        "\n",
        "Note: Code Block 14 is the Cross Validation function, Code Block 15 and Code Block 20 used this Cross Validation Function.\n"
      ],
      "metadata": {
        "id": "VZX7lRA7hSHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code Block 1\n",
        "Global libraries\n",
        "'''\n",
        "from pathlib import Path\n",
        "import glob\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import pickle\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "3JGAsUV0pUiX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code Block 2\n",
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPYMFDydC9f0",
        "outputId": "b3b14fa0-5818-4709-fc17-c3a46a4d4cbb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code Block 3\n",
        "Data Augmentation\n",
        "'''\n",
        "\n",
        "### gamma correction\n",
        "def gamma_correction(image, gamma):\n",
        "  invGamma = 1.0 / gamma\n",
        "  table = np.array([((i / 255.0) ** invGamma) * 255\n",
        "\t\tfor i in np.arange(0, 256)]).astype(\"uint8\")\n",
        "\n",
        "  new_img = cv2.LUT(image, table)\n",
        "  return new_img\n",
        "\n",
        "### augmentation method 1 - horizontal flip\n",
        "def horizontal_flip(img):\n",
        "  img = cv2.flip(img, 0)\n",
        "  return img\n",
        "\n",
        "### augmentation method 2 - vertical flip\n",
        "def vertical_flip(img):\n",
        "  img = cv2.flip(img,1)\n",
        "  return img\n",
        "\n",
        "### augmentation method 3 - Histogram Equalization\n",
        "def hist(img):\n",
        "  img_to_yuv = cv2.cvtColor(img,cv2.COLOR_BGR2YUV)\n",
        "  img_to_yuv[:,:,0] = cv2.equalizeHist(img_to_yuv[:,:,0])\n",
        "  hist_equalization_result = cv2.cvtColor(img_to_yuv, cv2.COLOR_YUV2BGR)\n",
        "  return hist_equalization_result\n",
        "\n",
        "### augmentation method 4 - rotation\n",
        "def rotation(img):\n",
        "  h,w = img.shape[:2]\n",
        "  rotation_matrix = cv2.getRotationMatrix2D((w/2,h/2),45,0.5)\n",
        "  rotated_img = cv2.warpAffine(img,rotation_matrix,(w,h))\n",
        "  return rotated_img\n",
        "\n",
        "def rotation2(img):\n",
        "  h,w = img.shape[:2]\n",
        "  rotation_matrix = cv2.getRotationMatrix2D((w/2,h/2),135,0.5)\n",
        "  rotated_img = cv2.warpAffine(img,rotation_matrix,(w,h))\n",
        "  return rotated_img\n",
        "\n",
        "def rotation3(img):\n",
        "  h,w = img.shape[:2]\n",
        "  rotation_matrix = cv2.getRotationMatrix2D((w/2,h/2),235,0.5)\n",
        "  rotated_img = cv2.warpAffine(img,rotation_matrix,(w,h))\n",
        "  return rotated_img\n",
        "\n",
        "### augmentation method 5 - increase brightness\n",
        "def increase_brightness(img):\n",
        "  bright = np.ones(img.shape, dtype='uint8')*70\n",
        "  increase_brightness = cv2.add(img,bright)\n",
        "  return increase_brightness\n",
        "def increase_brightness2(img):\n",
        "  bright = np.ones(img.shape, dtype='uint8')*100\n",
        "  increase_brightness = cv2.add(img,bright)\n",
        "  return increase_brightness\n",
        "def increase_brightness3(img):\n",
        "  bright = np.ones(img.shape, dtype='uint8')*140\n",
        "  increase_brightness = cv2.add(img,bright)\n",
        "  return increase_brightness\n",
        "\n",
        "### augmentation method 6 - decrease brightness\n",
        "def decrease_brightness(img):\n",
        "  bright = np.ones(img.shape, dtype='uint8')*70\n",
        "  decrease_brightness = cv2.subtract(img,bright)\n",
        "  return decrease_brightness\n",
        "def decrease_brightness2(img):\n",
        "  bright = np.ones(img.shape, dtype='uint8')*140\n",
        "  decrease_brightness = cv2.subtract(img,bright)\n",
        "  return decrease_brightness\n",
        "def decrease_brightness3(img):\n",
        "  bright = np.ones(img.shape, dtype='uint8')*140\n",
        "  decrease_brightness = cv2.subtract(img,bright)\n",
        "  return decrease_brightness"
      ],
      "metadata": {
        "id": "30bIvkTcl4WD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code Block 4\n",
        "Detecting the faces from an image.\n",
        "Return a list containing only faces, each face image size is 50x50.\n",
        "'''\n",
        "\n",
        "def face_extract_function(image):\n",
        "  res_face_list = []\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "  faces = face_cascade.detectMultiScale(gray, 1.1, 7)\n",
        "  for (x, y, w, h) in faces:\n",
        "    cv2.rectangle(image, (x, y), (x+w, y+h),\n",
        "                  (0, 0, 255), 2)\n",
        "    face = image[y:y + h, x:x + w]\n",
        "    resized_face = cv2.resize(face, (50, 50))\n",
        "    res_face_list.append(resized_face)\n",
        "  return res_face_list"
      ],
      "metadata": {
        "id": "6ZDv3XRgFQPc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code Block 5\n",
        "'''\n",
        "categories = ['Abdullah Khan', 'Akshat Kalra', 'Bowen Cheng', 'Chakrapani Chitnis', 'Chin Fang Hsu',\n",
        "              'Edison Nalluri', 'Kai Cong', 'Kyle Fenole', 'Landis Fusato', 'Minghao Zhang', 'Mohit Jawale',\n",
        "              'Patrick Lee', 'Peiyuan Li', 'Rahim Firoz Chunara', 'Rohan Vikas Lagare', 'Sadwi Kandula',\n",
        "              'Samuel Anderson', 'Shaunak Chaudhary', 'Tampara Venkara Santosh Anish Dora', 'Weixuan Lin',\n",
        "              'Xinyu Dong', 'Yaoyao Peng', 'Yufan Lin']"
      ],
      "metadata": {
        "id": "RUSRZ-gERoF6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code Block 6\n",
        "1. Processing the image, read the image from the drive\n",
        "2. Crop the image, leave only student faces.\n",
        "3. Convert the image to a numpy array.\n",
        "4. Dump the image data to a file as dataset.\n",
        "'''\n",
        "\n",
        "data = []\n",
        "dir = '/content/drive/MyDrive/COEN 240/Project/Photos/' # ----- Need to switch this directory path to where your Training photo saved. -----\n",
        "counter = 0\n",
        "# constructing the data structure for all student pictures.\n",
        "for category in categories: #category is student name\n",
        "  path = dir + category\n",
        "  image_dir = Path(path)\n",
        "  label = categories.index(category)\n",
        "  image_dir_list = image_dir.glob(\"*.*\") # read the image in all type, *.png and 8.jpg\n",
        "  for image in image_dir_list:\n",
        "    counter += 1\n",
        "    student_image = cv2.imread(str(image))\n",
        "    student_face_extract = face_extract_function(student_image)\n",
        "    for img in student_face_extract:\n",
        "      #normalization\n",
        "      img = hist(img)\n",
        "\n",
        "      original_img = np.array(img).flatten()\n",
        "      data.append([original_img, label])\n",
        "\n",
        "      #horizontal_flip_img = np.array(horizontal_flip(img)).flatten()\n",
        "      #data.append([horizontal_flip_img, label])\n",
        "\n",
        "      #vertical_flip_img = np.array(vertical_flip(img)).flatten()\n",
        "      #data.append([vertical_flip_img, label])\n",
        "\n",
        "      #Decrease accuracy\n",
        "      rotated_img = np.array(rotation(img)).flatten()\n",
        "      data.append([rotated_img, label])\n",
        "      rotated_img2 = np.array(rotation2(img)).flatten()\n",
        "      data.append([rotated_img2, label])\n",
        "      rotated_img3 = np.array(rotation3(img)).flatten()\n",
        "      data.append([rotated_img3, label])\n",
        "\n",
        "      increase_brightness_img = np.array(increase_brightness(img)).flatten()\n",
        "      data.append([increase_brightness_img, label])\n",
        "      increase_brightness_img2 = np.array(increase_brightness2(img)).flatten()\n",
        "      data.append([increase_brightness_img2, label])\n",
        "      increase_brightness_img3 = np.array(increase_brightness3(img)).flatten()\n",
        "      data.append([increase_brightness_img3, label])\n",
        "\n",
        "      decrease_brightness_img = np.array(decrease_brightness(img)).flatten()\n",
        "      data.append([decrease_brightness_img, label])\n",
        "      decrease_brightness_img2 = np.array(decrease_brightness2(img)).flatten()\n",
        "      data.append([decrease_brightness_img2, label])\n",
        "      decrease_brightness_img3 = np.array(decrease_brightness3(img)).flatten()\n",
        "      data.append([decrease_brightness_img3, label])\n",
        "\n",
        "      #gamma correction - gamma value = 0.5\n",
        "      np.array(decrease_brightness2(img)).flatten()\n",
        "      gamma_correction_img = np.array(gamma_correction(img, 0.5)).flatten()\n",
        "      data.append([gamma_correction_img, label])\n",
        "\n",
        "      #gamma correction - gamma value = 0.25\n",
        "      np.array(decrease_brightness2(img)).flatten()\n",
        "      gamma_correction_img = np.array(gamma_correction(img, 0.25)).flatten()\n",
        "      data.append([gamma_correction_img, label])\n",
        "\n",
        "      #gamma correction - gamma value = 0.75\n",
        "      np.array(decrease_brightness2(img)).flatten()\n",
        "      gamma_correction_img = np.array(gamma_correction(img, 0.75)).flatten()\n",
        "      data.append([gamma_correction_img, label])\n",
        "\n",
        "pick_in = open('/content/drive/MyDrive/COEN 240/Project/dataset.pickle', 'wb')\n",
        "pickle.dump(data, pick_in)\n",
        "pick_in.close()\n"
      ],
      "metadata": {
        "id": "WrZ1gzHsO7Sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code Block 7\n",
        "'''\n",
        "### Load the testing data\n",
        "\n",
        "dir = '/content/drive/MyDrive/COEN 240/Project/Testing_Photos/' # ----- Need to switch this directory path to where your Testing photo saved. -----\n",
        "# constructing the data structure for all student pictures.\n",
        "data = []\n",
        "for category in categories: #category is student name\n",
        "  path = dir + category\n",
        "  image_dir = Path(path)\n",
        "  label = categories.index(category)\n",
        "  image_dir_list = image_dir.glob(\"*.*\") # read the image in all type, *.png and 8.jpg\n",
        "  for image in image_dir_list:\n",
        "    student_image = cv2.imread(str(image))\n",
        "    student_face_extract = face_extract_function(student_image)\n",
        "    for img in student_face_extract:\n",
        "      original_img = np.array(img).flatten()\n",
        "      data.append([original_img, label])\n",
        "\n",
        "pick_in = open('/content/drive/MyDrive/COEN 240/Project/test_dataset.pickle', 'wb')\n",
        "pickle.dump(data, pick_in)\n",
        "pick_in.close()\n"
      ],
      "metadata": {
        "id": "M0KJwamtDQws"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code Block 8\n",
        "'''\n",
        "### Load the Training dataset\n",
        "pick_in = open('/content/drive/MyDrive/COEN 240/Project/dataset.pickle', 'rb')\n",
        "data = pickle.load(pick_in)\n",
        "pick_in.close()\n",
        "\n",
        "random.shuffle(data)\n",
        "X_train = []\n",
        "y_train = []\n",
        "for feature, label in data:\n",
        "  feature = feature.flatten()\n",
        "  X_train.append(feature)\n",
        "  y_train.append(label)"
      ],
      "metadata": {
        "id": "1Ds4O4RAqKCP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code Block 9\n",
        "'''\n",
        "### Load testing dataset\n",
        "pick_in = open('/content/drive/MyDrive/COEN 240/Project/test_dataset.pickle', 'rb')\n",
        "data = pickle.load(pick_in)\n",
        "pick_in.close()\n",
        "\n",
        "X_test = []\n",
        "y_test = []\n",
        "for feature, label in data:\n",
        "  feature = feature.flatten()\n",
        "  X_test.append(feature)\n",
        "  y_test.append(label)\n"
      ],
      "metadata": {
        "id": "AeWT77A-uE9M"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code Block 10\n",
        "'''\n",
        "### Feature extraction for training the model\n",
        "pca = PCA(n_components=100)\n",
        "pca.fit(X_train)"
      ],
      "metadata": {
        "id": "QW5CgssvBToz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "f0f5b14c-bc2c-47da-bc5b-20f39c579bad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(n_components=100)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=100)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code Block 11\n",
        "'''\n",
        "### Transform X_train and X_test to the designate shape\n",
        "X_train = pca.transform(X_train)\n",
        "X_test_data = pca.transform(X_test)\n"
      ],
      "metadata": {
        "id": "VOul3rq2qet7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code Block 12\n",
        "'''\n",
        "# SVM\n",
        "svm_model = SVC(C = 1000, gamma = 'auto', kernel = 'rbf')\n",
        "svm_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "8YrIrN8jHSQA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "5b9eead9-efa2-4168-97f4-3fbd8cdf00f3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1000, gamma='auto')"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1000, gamma=&#x27;auto&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1000, gamma=&#x27;auto&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code Block 13\n",
        "'''\n",
        "predictions = svm_model.predict(X_test_data)\n",
        "print(accuracy_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvKii3WbI914",
        "outputId": "4b94de06-5876-410d-fe3d-aaa37178ce05"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.09722222222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code Block 14\n",
        "'''\n",
        "# K-Fold Cross-Validation\n",
        "from sklearn.model_selection import cross_validate\n",
        "def cross_validation(model, _X, _y, _cv = 10):\n",
        "  results = cross_validate(estimator=model,\n",
        "                               X=_X,\n",
        "                               y=_y,\n",
        "                               cv=_cv,\n",
        "                               scoring='accuracy',\n",
        "                               return_train_score=True)\n",
        "  print(\"Mean Training Accuracy:\", results['train_score'].mean()*100)\n",
        "  print(\"Mean Testing Accuracy:\", results['test_score'].mean()*100)"
      ],
      "metadata": {
        "id": "QHz6rMPpFN0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code Block 15\n",
        "'''\n",
        "# KNN (n=1 has better average accuracy than 3 and 5)\n",
        "knn_model = KNeighborsClassifier(n_neighbors=1)\n",
        "cross_validation(knn_model,X_train,y_train)\n",
        "knn_model2 = KNeighborsClassifier(n_neighbors=1)\n",
        "cross_validation(knn_model2,X_train,y_train)\n",
        "knn_model3 = KNeighborsClassifier(n_neighbors=3)\n",
        "cross_validation(knn_model3,X_train,y_train)\n",
        "knn_model4 = KNeighborsClassifier(n_neighbors=5)\n",
        "cross_validation(knn_model4,X_train,y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZ6EfrsyoVuZ",
        "outputId": "8c0440e8-9946-4ac6-cc1d-4f43f24d8bc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Training Accuracy: 100.0\n",
            "Mean Testing Accuracy: 87.93821343752396\n",
            "Mean Training Accuracy: 100.0\n",
            "Mean Testing Accuracy: 87.93821343752396\n",
            "Mean Training Accuracy: 91.75892718210838\n",
            "Mean Testing Accuracy: 77.58101585842336\n",
            "Mean Training Accuracy: 85.05243378584193\n",
            "Mean Testing Accuracy: 74.040258944304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code Block 16\n",
        "'''\n",
        "# KNN (n=1 has better average accuracy than 3 and 5)\n",
        "knn_model = KNeighborsClassifier(n_neighbors=1)\n",
        "knn_model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "qRIikcd4ePZb",
        "outputId": "3cf48589-3784-4efa-e0d1-561d7a4401a5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=1)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code Block 17\n",
        "'''\n",
        "predictions = knn_model.predict(X_test_data)\n",
        "print(accuracy_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzQ5g7Jnet8P",
        "outputId": "c6b14d2e-b47b-4f4f-f575-cb0eecc326c4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6527777777777778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code Block 18\n",
        "'''\n",
        "### Decision tree\n",
        "decision_tree_model = DecisionTreeClassifier(random_state=0)\n",
        "decision_tree_model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "ELEgBvzLe31_",
        "outputId": "69b6c6c1-db7d-44ba-cb8f-678c9b1a827f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code Block 19\n",
        "'''\n",
        "predictions = decision_tree_model.predict(X_test_data)\n",
        "print(accuracy_score(y_test,predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3VTRqvEfVY3",
        "outputId": "67b1092d-2aeb-468f-c3b5-af0f7c4b37a1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code Block 20\n",
        "'''\n",
        "# Random forest\n",
        "# limit max depth to prevent overfitting\n",
        "random_forest_model = RandomForestClassifier(class_weight = 'balanced', random_state=0, max_depth = 15)\n",
        "\n",
        "cross_validation(random_forest_model,X_train,y_train)\n",
        "\n",
        "random_forest_model2 = RandomForestClassifier( class_weight = 'balanced', random_state=0, max_depth = 8)\n",
        "cross_validation(random_forest_model2,X_train,y_train)\n",
        "\n",
        "random_forest_model3 = RandomForestClassifier( class_weight = 'balanced', random_state=0, max_depth = 10)\n",
        "cross_validation(random_forest_model3,X_train,y_train)\n",
        "\n",
        "random_forest_model4 = RandomForestClassifier( class_weight = 'balanced', random_state=0, max_depth = 12)\n",
        "cross_validation(random_forest_model4,X_train,y_train)\n",
        "\n",
        "random_forest_model5 = RandomForestClassifier( class_weight = 'balanced', random_state=0, max_depth = 15)\n",
        "cross_validation(random_forest_model5,X_train,y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZubZr0ThqUfI",
        "outputId": "082f2e97-ddbc-48dd-a26d-c96f1737353b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Training Accuracy: 100.0\n",
            "Mean Testing Accuracy: 86.66992262315176\n",
            "Mean Training Accuracy: 96.68808970326815\n",
            "Mean Testing Accuracy: 82.2561863173217\n",
            "Mean Training Accuracy: 99.67948433823565\n",
            "Mean Testing Accuracy: 84.31012027886308\n",
            "Mean Training Accuracy: 99.97571872480279\n",
            "Mean Testing Accuracy: 85.7088408794913\n",
            "Mean Training Accuracy: 100.0\n",
            "Mean Testing Accuracy: 86.66992262315176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code Block 21\n",
        "'''\n",
        "### Random forest\n",
        "random_forest_model = RandomForestClassifier( class_weight = 'balanced', random_state=0,max_depth = 15, n_estimators=400)\n",
        "random_forest_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "iJPyD4FlfmTn",
        "outputId": "55654090-c0c2-4a24-ed0c-f60c4c4b91e5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(class_weight='balanced', max_depth=15, n_estimators=400,\n",
              "                       random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=15, n_estimators=400,\n",
              "                       random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=15, n_estimators=400,\n",
              "                       random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code Block 22\n",
        "'''\n",
        "predictions = random_forest_model.predict(X_test_data)\n",
        "print(accuracy_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5cBRkR5f4dr",
        "outputId": "3a0272bc-d560-416c-947b-e7983ef48eb9"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5416666666666666\n"
          ]
        }
      ]
    }
  ]
}